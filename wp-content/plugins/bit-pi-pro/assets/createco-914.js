import{a3 as r,a4 as i}from"./_applist-952.js";import{_ as e}from"./main-red-poems-invite.js";import{s as p}from"./machine.-578.js";import{h as m,a as s,c as E,f as l}from"./machineh-619.js";import"./lodash-840.js";import"./mutative-12.js";globalThis.jotaiAtomCache=globalThis.jotaiAtomCache||{cache:new Map,get(a,t){return this.cache.has(a)?this.cache.get(a):(this.cache.set(a,t),t)}};const C=r(({helpers:a})=>({states:{components:[E(a),{componentName:a.componentName.select,helperText:e("Choose the claude model to use here."),id:"model",label:e("Model"),onChange:"SELECT_MODEL",onRefetch:"REFETCH_MODEL",optionFilterProp:"label",options:[],path:"model",placeholder:e("Select a Model"),render:"IF_CONNECTION_SELECTED",showSearch:!0,value:void 0},{addItemButtonLabel:"Add Message",componentName:a.componentName.repeaterField,fieldsMetaData:[{componentName:a.componentName.select,label:e("Role"),name:"role",options:[{label:e("User"),value:"user"},{label:e("Assistant"),value:"assistant"}],showSearch:!0,style:{width:120},value:""},{componentName:a.componentName.mixInput,label:e("Message"),name:"value",value:[],wrapperClassName:"w-100"}],id:"message-field-properties",label:e("Messages"),onChange:"SET_MESSAGE_FIELD",path:"messageFieldProperties",render:"IF_CONNECTION_SELECTED",value:[]},{componentName:a.componentName.switch,fieldType:"config",id:"show-advance-feature",label:e("Show Advance Feature"),onChange:"SET_FEATURE",render:"IF_CONNECTION_SELECTED",value:!1},{componentName:a.componentName.mixInput,helperText:e("Enter the maximum token limit, though models may stop before reaching it; varies across models."),id:"max-token",label:e("Max Token"),onChange:"SET_MAX_TOKEN",path:"max_tokens",placeholder:e("Enter the token value"),render:"IF_ADVANCE_FEATURE_SELECTED",value:void 0},{componentName:a.componentName.mixInput,helperText:e("Enter temperature to tune response randomness (0.0 to 1.0): 0.0 for analytical, 1.0 for creative tasks. Note: Full determinism is not guaranteed even at 0.0."),id:"temperature-val",label:e("Temperatures"),onChange:"SET_TEMPERATURE",path:"temperature",placeholder:e("Enter temperature value"),render:"IF_ADVANCE_FEATURE_SELECTED",value:void 0},{componentName:a.componentName.mixInput,helperText:e("Enter nucleus sampling with top_p for probability cutoff. Adjust temperature or top_p, not both. Temperature is usually sufficient, controlling randomness, while top_p manages content diversity, ideal for advanced scenarios like creative writing. E.g. 1."),id:"topP-val",label:e("topP Sampling Value"),onChange:"SET_TOP_P",path:"top_p",placeholder:e("Enter topP value"),render:"IF_ADVANCE_FEATURE_SELECTED",value:void 0},{componentName:a.componentName.mixInput,helperText:e('Enter only a sample from the top K options for each subsequent token. Used to remove "long tail" low probability responses. Recommended for advanced use cases only. You usually only need to use temperature.'),id:"topK-val",label:e("topK Sampling Value"),onChange:"SET_TOP_K",path:"top_k",placeholder:e("Enter topK value"),render:"IF_ADVANCE_FEATURE_SELECTED",value:void 0},{componentName:a.componentName.mixInput,helperText:e(`Define custom stop sequences to interrupt the model's generation. By using the stop_sequences parameter, the model will halt when it encounters specified text strings, with the response stop_reason as "stop_sequence" and the matched sequence in stop_sequence value.`),id:"stop-sequence",label:e("Stop Sequence"),onChange:"SET_STOP_SEQUENCE",path:"stop_sequences",placeholder:e("Enter stop sequences"),render:"IF_ADVANCE_FEATURE_SELECTED",value:void 0}]},actions:{IF_ADVANCE_FEATURE_SELECTED:({$:t})=>{var o;return((o=t.getComponent("show-advance-feature"))==null?void 0:o.value)===!0},IF_CONNECTION_SELECTED:({$:t})=>{var o;return i((o=t.getComponent("connection-id"))==null?void 0:o.value)},ON_MACHINE_LOAD:async({$:t})=>{p(t,[{db:"connectionId",id:"connection-id"},{db:"modelId",id:"model"},{db:"maxToken",id:"max-token"},{db:"temperatureVal",id:"temperature-val"},{db:"topPVal",id:"topP-val"},{db:"topKVal",id:"topK-val"},{db:"messageFieldProperties",id:"message-field-properties"},{db:"showAdvanceFeature",id:"show-advance-feature"},{db:"stopSequence",id:"stop-sequence"}]),await l(t)},REFETCH_MODEL:async({$:t})=>{await l(t)},SELECT_MODEL:s("modelId"),SET_MAX_TOKEN:s("maxToken"),SET_MESSAGE_FIELD:s("messageFieldProperties"),SET_STOP_SEQUENCE:s("stopSequence"),SET_TEMPERATURE:s("temperatureVal"),SET_TOP_K:s("topKVal"),SET_TOP_P:s("topPVal"),SET_CONNECTION:async({$:t,e:o})=>{t.setThisComponent(n=>{n.value=o}),t.setDb(n=>{n.connectionId=o}),await l(t)},SET_FEATURE:async({$:t,e:o})=>{t.setThisComponent(n=>{n.value=o}),t.setDb(n=>{n.showAdvanceFeature=o})},CONNECTION_ADD_CHANGE:m}}));export{C as default};
